- https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese.pdf
- [综述.pdf](note/files/LLM_Survey_Chinese.pdf)。[English Version.pdf](note/files/English%20Version、.pdf)
- 为什么 LLM：在过去 20 年里，语言模型，。==统计语言模型==逐步发展成==神经语言模型==。接着在对 ==Transformer 模型==进行预训练 =  ==预训练模型（PLM）==，发现扩展模型规模可以提高模型能力。在扩展模型规模的过程中，出现了一些能力的涌现（比如上下文学习）。现在将模型规模达到百亿或者千亿的 PLM 称之为大语言模型（LLM）。我们关注 LLM 的 4 个主要方面：==预训练，适配微调，使用，能力评估==
- ==词的分布式表示== 
- word2vec 计算：
- Transformer 架构：
- 使用思维链（Chain of Thought) Can help LLM solve tasks which need to be solved step by step.
- 怎么避免 LLM 产出有害内容。
- LLM 对于文本以外形式的任务，表现不佳。所以可以支持插件形式，为 LLM 解决它不擅长的部分。相当于 LLM 的眼睛和耳朵。
- 强化学习（RL）： 近端策略优化 (Proximal Policy Optimization, PPO) 的论文在 2017 年 7 月发表 [81]，现在已经成为从人类偏好中学习的基础 RL 算法。
- 3 - 介绍了一些模型，不同规格的模型。 3.2 介绍了各种语料库。3.3 是代码库资源。
- 因果解码器架构采用单向注意力掩码？
- ICL 能力是什么能力？