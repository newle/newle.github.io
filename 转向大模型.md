# 看文档
- https://bytetech.info/articles/7371072158711480355#TIJndJ8BDoos8HxqRBGcoEDen0m
	- 《Thinking， fast and slow》 -- 大模型现在只有系统一的能力，也就是依靠直觉来生成下一个单词。我们希望来完善大模型的系统二的能力，赋予她更多逻辑性思考的能力。 
	- 将 LLM 类比成操作系统。
	- LLM 安全性：LLM 越狱。 Jailbreak
- https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/2/guidelines
	- 原则1
		- 使用各种符号来表达语意
		- 要求按格式输出
		- 可以用来判断是否满足特定的条件，如果满足的话，按特定条件输出。
		- 给问答队，让gpt follow一样的方式。
	- 原则2: 给 模型 一些时间进行思考。
		- 定义一下步骤，每个步骤要做的事情都定义清楚。
		- 让模型不要急于下结论。 - 判断对错，让模型自己做完，然后比对答案。
	- Hallucination - 幻觉问题
	- 不断迭代，修改prompt
	- Summarize:
		- 要求从某个角度总结，或者为某个角色总结。
	- Inferring：
		- 判断是positive 还是 negtive
		- 进行内容提取，文本分类，文本意图告警。
	- Transforming
		- 格式转变 - 翻译/语言类型判断/
		- 正式非正式
		- 对话变成信件
		- json to html
		- spell check  / grammar check
	- expanding
		- 要求按照特定的指令进行回复。
		- higher temprature -> more creativity 更随机 `response = get_completion(prompt, temperature=0.7)`
```python
# compare the differences between two sentences.

from redlines import Redlines
diff = Redlines(text,response)
display(Markdown(diff.output_markdown))
```
* ChatBot
```python
import os
import openai
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file

openai.api_key  = os.getenv('OPENAI_API_KEY')

def get_completion(prompt, model="gpt-3.5-turbo"):
    messages = [{"role": "user", "content": prompt}]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=0, # this is the degree of randomness of the model's output
    )
    return response.choices[0].message["content"]

def get_completion_from_messages(messages, model="gpt-3.5-turbo", temperature=0):
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=temperature, # this is the degree of randomness of the model's output
    )
#     print(str(response.choices[0].message))
    return response.choices[0].message["content"]

messages =  [  
{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},    
{'role':'user', 'content':'tell me a joke'},   
{'role':'assistant', 'content':'Why did the chicken cross the road'},   
{'role':'user', 'content':'I don\'t know'}  ]

response = get_completion_from_messages(messages, temperature=1)
print(response)



```

- 可以在这里使用 openai 的接口，做各种尝试，使用 Jupyter。 https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/2/guidelines 
- https://www.promptingguide.ai/zh/introduction/settings 提示词工程
	- 模型设置： temperature / Top_p - 越小返回的结果的确定性越高。 **Max Length**： 控制生成的token数量，可以控制成本。 **Stop Sequences**：控制列表的项的数目。**Frequency Penalty**：越高，则重复词出现的可能性越低。**Presence Penalty**：越高，防止重复词出现，和Frequency penalty 不同点在于，重复2次和重复10次是一样的。
	- 当使用 OpenAI 的 gpt-4 或者 gpt-3.5-turbo 等聊天模型时，您可以使用三个不同的角色来构建 prompt： system、user 和 assistant。
	- 使用小样本提示，会使得效果更好。
> This is awesome! // Positive
> This is bad! // Negative
> Wow that movie was rad! // Positive
> What a horrible show! //
回复： Negative
* think step by step.    通过 这个生成一个实例。 然后让新的问题也来think step by step
* 生成知识提示。 给一些样例，样例前面是关于知识，后面是关于推理，最后才是结论。
* COT / 自我一致性 / 生成知识提示 / prompt chaining / 思维树 / RAG / ART / 自动提示工程师 / Active prompt / 方向性刺激提示
* RAG：先搜索，然后将问题以及搜索结果一同送进大语言模型，优化答案。
* ART："让我们一步一步地解决这个问题，以确保我们有正确的答案。" 引发了思维链的推理，并提高了 MultiArith 和 GSM8K 基准测试的性能：
* ReAct: 对那些以推理为主要目标的任务 (例如 HotpotQA)，多思考-操作-观察步骤用于任务-解决轨迹。对于涉及许多操作步骤的决策任务来说，则较少使用思考
	* https://serper.dev/ 支持 google 的 api
```python
%%capture
# 更新或安装必要的库
!pip install --upgrade openai
!pip install --upgrade langchain
!pip install --upgrade python-dotenv
!pip install google-search-results
 
# 引入库
import openai
import os
from langchain.llms import OpenAI
from langchain.agents import load_tools
from langchain.agents import initialize_agent
from dotenv import load_dotenv
load_dotenv()
 
# 载入 API keys; 如果没有，你需要先获取。 
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["SERPER_API_KEY"] = os.getenv("SERPER_API_KEY")


llm = OpenAI(model_name="text-davinci-003" ,temperature=0)tools = load_tools(["google-serper", "llm-math"], llm=llm)agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)


# 
agent.run("奥利维亚·王尔德的男朋友是谁?他现在的年龄的0.23次方是多少?")

> 正在输入新代理执行器链......
  我得查出奥利维亚·王尔德的男友是谁然后计算出他的年龄的 0.23 次方。
操作: 搜索
操作输入: “奥利维亚·王尔德的男友”
观察: 奥利维亚·王尔德与杰森·苏代基斯在多年前订婚，在他们分手后，她开始与哈里·斯泰尔斯约会 — 参照他们的关系时间线。
思考: 我需要找出哈里·斯泰尔斯的年龄。
操作: 搜索
操作输入: “哈里·斯泰尔斯的年龄”
观察: 29 岁
思考: 我需要计算 29 的 0.23 次方。
操作: 计算器
操作输入: 29^0.23
观察: 答案: 2.169459462491557
 
思考: 现在我知道最终答案了。
最终答案: 哈里·斯泰尔斯, 奥利维亚·王尔德的男朋友, 29 岁。他年龄的 0.23 次方是 2.169459462491557。
 
> 结束链。

```
- Reflexion: ![](note/files/Pasted%20image%2020240807181503.png)总的来说，自我反思的关键步骤是a)定义任务，b)生成轨迹，c)评估，d)执行自我反思，e)生成下一条轨迹。下图展示了自我反思的智能体学习迭代优化其行为来解决决策、编程和推理等各种人物的例子。自我反思（Refelxion）通过引入自我评估、自我反思和记忆组件来拓展 ReAct 框架。
- 给予GPT生成函数
```
你好，ChatGPT！希望你一切都好。我正在寻求你的帮助，想要解决一个特定的功能。我知道你有处理信息和执行各种任务的能力，这是基于提供的指示。为了帮助你更容易地理解我的请求，我将使用一个模板来描述函数、输入和对输入的处理方法。请在下面找到详细信息：  
function_name：[函数名称]  
input：[输入]  
rule：[关于如何处理输入的说明]  
我恳请你根据我提供的细节为这个函数提供输出。非常感谢你的帮助。谢谢！  
我将使用方括号内的相关信息替换函数所需执行的内容。这个详细的介绍应该能够帮助你更高效地理解我的请求并提供所需的输出。格式是function_name(input)。如果你理解了，请用一个词回答"好的"


function_name: [trans_word]  
input: ["文本"]  
rule: [我希望你能扮演英文翻译员、拼写纠正员和改进员的角色。我将提供包含任何语言中"文本"的输入形式，你将检测语言，翻译并用英文纠正我的文本，并给出答案。]

function_name: [expand_word]  
input: ["文本"]  
rule: [请充当一个聊天机器人、拼写纠正员和语言增强员。我将提供包含任何语言中的"文本"的输入形式，并输出原始语言。我希望你保持意思不变，但使其更具文学性。]

function_name: [fix_english]  
input: ["文本"]  
rule: [请充当英文专家、拼写纠正员和语言增强员的角色。我将提供包含"文本"的输入形式，我希望你能改进文本的词汇和句子，使其更自然、更优雅。保持意思不变。]

trans_word('婆罗摩火山处于享有“千岛之国”美称的印度尼西亚. 多岛之国印尼有4500座之多的火山, 世界著名的十大活火山有三座在这里.')  
fix_english('Finally, you can run the function independently or chain them together.')  
fix_english(expand_word(trans_word('婆罗摩火山处于享有“千岛之国”美称的印度尼西亚. 多岛之国印尼有4500座之多的火山, 世界著名的十大活火山有三座在这里.')))

```

- openai 支持定义函数tools，以及需求。给出调用流程。实际调用过程还是需要用户自己来操作。
- https://bytedance.larkoffice.com/docx/PFIRd64hco77YMxUHZMcltSpnNh 个性化地搭建AI模型